{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5gcjsykizg9",
   "metadata": {},
   "source": "# Ray Core: Zero to Hero\n\nRay has **three primitives**. Everything else is built on top:\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                              RAY CORE                                   │\n├───────────────────────┬───────────────────────┬─────────────────────────┤\n│         TASKS         │        ACTORS         │      OBJECT STORE       │\n│                       │                       │                         │\n│  Stateless functions  │  Stateful objects     │  Shared memory that     │\n│  that run in parallel │  that live on workers │  holds all the data     │\n├───────────────────────┴───────────────────────┴─────────────────────────┤\n│                                                                         │\n│  \"I want to run this    \"I need state that     \"How do tasks and        │\n│   function 1000 times\"   persists across calls\" actors share data?\"     │\n│                                                                         │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 1. The Problem: Sequential Python is Slow"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bbdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local (sequential): 4.0s\n",
      "Results: [0, 1, 4, 9, 16, 25, 36, 49]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def slow_square(x):\n",
    "    time.sleep(0.5)\n",
    "    return x * x\n",
    "\n",
    "start = time.time()\n",
    "results = [slow_square(i) for i in range(8)]\n",
    "print(f\"Local (sequential): {time.time() - start:.1f}s\")\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h3wmkc6fwd",
   "metadata": {},
   "source": "---\n\n## 2. Starting Ray\n\nWhen you call `ray.init()`, Ray starts a local cluster:\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                              YOUR MACHINE                               │\n│                                                                         │\n│  ┌─────────────────────────────────────────────────────────────────┐   │\n│  │                         HEAD NODE                                │   │\n│  │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  │   │\n│  │  │  GCS (metadata) │  │     Raylet      │  │  Object Store   │  │   │\n│  │  │                 │  │   (scheduler)   │  │ (shared memory) │  │   │\n│  │  └─────────────────┘  └─────────────────┘  └─────────────────┘  │   │\n│  └─────────────────────────────────────────────────────────────────┘   │\n│                                    │                                    │\n│            ┌───────────────────────┼───────────────────────┐            │\n│            ▼                       ▼                       ▼            │\n│     ┌───────────┐           ┌───────────┐           ┌───────────┐      │\n│     │  Worker   │           │  Worker   │           │  Worker   │      │\n│     │ (Python)  │           │ (Python)  │           │ (Python)  │      │\n│     └───────────┘           └───────────┘           └───────────┘      │\n│                                                                         │\n│  Key: Same code scales to 1000-node cluster without changes!            │\n└─────────────────────────────────────────────────────────────────────────┘\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-01 21:00:22,292\tINFO worker.py:1839 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node:__internal_head__': 1.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 1073741824.0, 'CPU': 4.0, 'memory': 9329328128.0}\n"
     ]
    }
   ],
   "source": [
    "# How to start ray\n",
    "import ray\n",
    "\n",
    "ray.init(num_cpus=4, # MAKE SURE TO SET THIS TO THE NUMBER OF CPUS YOU WANT TO USE\n",
    "         # limit the object store memory to 1GB for this example\n",
    "         object_store_memory=1 * 1024 * 1024 * 1024,\n",
    "         ignore_reinit_error=True)  # Connect to an existing Ray cluster\n",
    "\n",
    "print(ray.cluster_resources())  # Print the cluster resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rzuxj5s14k",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Tasks: Parallel Functions\n",
    "\n",
    "A **task** is a function decorated with `@ray.remote`. Calling `.remote()` returns immediately with an `ObjectRef` (a future/promise).\n",
    "\n",
    "```\n",
    "SEQUENTIAL (Python default)              PARALLEL (Ray)\n",
    "┌─────────────────────────────┐         ┌─────────────────────────────┐\n",
    "│                             │         │                             │\n",
    "│  task(0) ████               │         │  task(0) ████               │\n",
    "│  task(1)     ████           │         │  task(1) ████               │\n",
    "│  task(2)         ████       │         │  task(2) ████               │\n",
    "│  task(3)             ████   │         │  task(3) ████               │\n",
    "│                             │         │                             │\n",
    "│  Total: 4 units             │         │  Total: 1 unit              │\n",
    "└─────────────────────────────┘         └─────────────────────────────┘\n",
    "```\n",
    "\n",
    "**The pattern:**\n",
    "```python\n",
    "# 1. Decorate with @ray.remote\n",
    "@ray.remote\n",
    "def my_function(x):\n",
    "    return x * 2\n",
    "\n",
    "# 2. Call with .remote() - returns immediately with ObjectRef\n",
    "ref = my_function.remote(5)  # Non-blocking!\n",
    "\n",
    "# 3. Get result with ray.get() - blocks until ready\n",
    "result = ray.get(ref)  # 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray (parallel): 1.0s\n",
      "Results: [0, 1, 4, 9, 16, 25, 36, 49]\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def slow_square_ray(x):\n",
    "    \"\"\"Same function, but runs on Ray workers\"\"\"\n",
    "    time.sleep(0.5)\n",
    "    return x * x\n",
    "\n",
    "# Run 8 tasks on Ray (in parallel)\n",
    "start = time.time()\n",
    "futures = [slow_square_ray.remote(i) for i in range(8)]  # Schedule all 8 instantly\n",
    "# This blocks until the results are ready\n",
    "results = ray.get(futures)  # Wait for all to finish\n",
    "print(f\"Ray (parallel): {time.time() - start:.1f}s\")\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aselx739z7",
   "metadata": {},
   "source": [
    "### Task Dependencies (DAGs)\n",
    "\n",
    "Tasks can depend on other tasks. Ray automatically figures out the execution order.\n",
    "\n",
    "```\n",
    "The execution graph:\n",
    "\n",
    "fetch(\"db\")  ──► process() ──┐\n",
    "                             │\n",
    "fetch(\"api\") ──► process() ──┼──► combine() ──► result\n",
    "                             │\n",
    "fetch(\"cache\")─► process() ──┘\n",
    "\n",
    "Time: ─────────────────────────────────────────────────►\n",
    "      |── 1s fetch ──|── 1s process ──|── 0.5s ──|\n",
    "      (all parallel)   (all parallel)   combine\n",
    "      \n",
    "Total: 2.5s (not 7.5s if sequential!)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d156481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(fetch_data pid=8068)\u001b[0m [21:01:08.949] Fetching from api...\n",
      "\u001b[36m(fetch_data pid=8071)\u001b[0m [21:01:08.949] Fetching from cache...\n",
      "\u001b[36m(fetch_data pid=8070)\u001b[0m [21:01:08.949] Fetching from db...\n",
      "\u001b[36m(fetch_data pid=8068)\u001b[0m [21:01:09.950] Fetched api\n",
      "\u001b[36m(process pid=8068)\u001b[0m [21:01:09.957] Processing data_from_db...\n",
      "\u001b[36m(fetch_data pid=8071)\u001b[0m [21:01:09.950] Fetched cache\n",
      "\u001b[36m(process pid=8071)\u001b[0m [21:01:09.957] Processing data_from_cache...\n",
      "\u001b[36m(fetch_data pid=8070)\u001b[0m [21:01:09.950] Fetched db\n",
      "\u001b[36m(process pid=8070)\u001b[0m [21:01:09.954] Processing data_from_api...\n",
      "\u001b[36m(combine pid=8069)\u001b[0m [21:01:10.960] Combining: ['processed(data_from_db)', 'processed(data_from_api)', 'processed(data_from_cache)']\n",
      "\u001b[36m(process pid=8068)\u001b[0m [21:01:10.958] Processed data_from_db\n",
      "\u001b[36m(process pid=8071)\u001b[0m [21:01:10.958] Processed data_from_cache\n",
      "\u001b[36m(process pid=8070)\u001b[0m [21:01:10.955] Processed data_from_api\n",
      "\n",
      "Total time: 2.5s\n",
      "Result: combined(['processed(data_from_db)', 'processed(data_from_api)', 'processed(data_from_cache)'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(combine pid=8069)\u001b[0m [21:01:11.461] Combined!\n"
     ]
    }
   ],
   "source": [
    "# Task Dependencies (DAG)\n",
    "# Tasks can depend on other tasks: fetch -> process -> combine\n",
    "\n",
    "import datetime\n",
    "\n",
    "def timestamp():\n",
    "    return datetime.datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "\n",
    "@ray.remote\n",
    "def fetch_data(source):\n",
    "    print(f\"[{timestamp()}] Fetching from {source}...\")\n",
    "    time.sleep(1)\n",
    "    print(f\"[{timestamp()}] Fetched {source}\")\n",
    "    return f\"data_from_{source}\"\n",
    "\n",
    "@ray.remote\n",
    "def process(data):\n",
    "    print(f\"[{timestamp()}] Processing {data}...\")\n",
    "    time.sleep(1)\n",
    "    print(f\"[{timestamp()}] Processed {data}\")\n",
    "    return f\"processed({data})\"\n",
    "\n",
    "@ray.remote\n",
    "def combine(results):\n",
    "    resolved = ray.get(results)\n",
    "    print(f\"[{timestamp()}] Combining: {resolved}\")\n",
    "    time.sleep(0.5)\n",
    "    print(f\"[{timestamp()}] Combined!\")\n",
    "    return f\"combined({resolved})\"\n",
    "\n",
    "start = time.time()\n",
    "data_refs = [fetch_data.remote(s) for s in [\"db\", \"api\", \"cache\"]]\n",
    "processed_refs = [process.remote(d) for d in data_refs]\n",
    "final = combine.remote(processed_refs)\n",
    "\n",
    "result = ray.get(final)\n",
    "print(f\"\\nTotal time: {time.time() - start:.1f}s\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97vqzz6mdu6",
   "metadata": {},
   "source": [
    "### `ray.wait()`: Process Results as They Arrive\n",
    "\n",
    "`ray.get(refs)` blocks until **ALL** results are ready. Sometimes you want to process results as they complete:\n",
    "\n",
    "```\n",
    "ray.get([refs])              vs           ray.wait(refs)\n",
    "┌────────────────────────┐               ┌────────────────────────┐\n",
    "│ task1 ████             │               │ task1 ████ -> process! │\n",
    "│ task2 ████████████     │               │ task2 ████████████     │\n",
    "│ task3 ██████           │               │ task3 ██████ -> process│\n",
    "│                        │               │        ...             │\n",
    "│ (wait for ALL)    ▼    │               │ (process as ready) ▼   │\n",
    "│ process results        │               │ task2 done -> process! │\n",
    "└────────────────────────┘               └────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55629dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got result: 3\n",
      "Got result: 0\n",
      "Got result: 2\n",
      "Got result: 1\n",
      "Got result: 5\n",
      "Got result: 4\n",
      "Got result: 6\n",
      "Got result: 8\n",
      "Got result: 7\n",
      "Got result: 9\n"
     ]
    }
   ],
   "source": [
    "# Don't block on everything finishing\n",
    "@ray.remote\n",
    "def variable_time_task(i):\n",
    "    import time, random\n",
    "    time.sleep(random.uniform(0.1, 2.0))\n",
    "    return i\n",
    "\n",
    "refs = [variable_time_task.remote(i) for i in range(10)]\n",
    "\n",
    "# Process results as they complete\n",
    "while refs:\n",
    "    # Wait for the next task to complete\n",
    "    ready, refs = ray.wait(refs, num_returns=1)\n",
    "    result = ray.get(ready[0])\n",
    "    print(f\"Got result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd08e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Actors: Stateful Objects\n",
    "\n",
    "Tasks are stateless - each invocation is independent. But sometimes you need:\n",
    "- State that persists across calls (counters, caches, ML models)\n",
    "- A resource that shouldn't be recreated (database connections, GPU memory)\n",
    "- Coordination between operations (locks, queues)\n",
    "\n",
    "**Actors** are the answer: classes decorated with `@ray.remote`.\n",
    "\n",
    "```\n",
    "TASKS (stateless)                        ACTORS (stateful)\n",
    "┌─────────────────────────────┐         ┌─────────────────────────────┐\n",
    "│                             │         │                             │\n",
    "│  @ray.remote                │         │  @ray.remote                │\n",
    "│  def func(x):               │         │  class Counter:             │\n",
    "│      return x * 2           │         │      def __init__(self):    │\n",
    "│                             │         │          self.count = 0     │\n",
    "│  # Each call independent    │         │                             │\n",
    "│  # No memory between calls  │         │      def increment(self):   │\n",
    "│                             │         │          self.count += 1    │\n",
    "│                             │         │          return self.count  │\n",
    "│                             │         │                             │\n",
    "│                             │         │  # State persists!          │\n",
    "└─────────────────────────────┘         └─────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Tasks vs Actors: When to Use What\n",
    "\n",
    "| Use **Tasks** when...              | Use **Actors** when...              |\n",
    "|------------------------------------|-------------------------------------|\n",
    "| Function is pure (no side effects) | Need state across calls             |\n",
    "| Each call is independent           | Need to coordinate operations       |\n",
    "| Can recreate any required state    | Hold expensive resources (GPU, DB)  |\n",
    "| Want automatic load balancing      | Need predictable placement          |\n",
    "| Embarrassingly parallel workloads  | Stateful services (caches, models)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a411e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter after increment: 11\n",
      "[12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "class Counter:\n",
    "    def __init__(self, start=0):\n",
    "        self.value = start\n",
    "\n",
    "    def increment(self):\n",
    "        self.value += 1\n",
    "        return self.value\n",
    "\n",
    "    def get(self):\n",
    "        return self.value\n",
    "    \n",
    "# Create a counter actor\n",
    "# Pass starting value = 10\n",
    "counter = Counter.remote(start=10)\n",
    "# call methods on the actor\n",
    "ref = counter.increment.remote()\n",
    "print(f\"Counter after increment: {ray.get(ref)}\")\n",
    "\n",
    "#Multiple calls maintin state\n",
    "refs = [counter.increment.remote() for _ in range(5)]\n",
    "print(ray.get(refs))  # [12, 13, 14, 15, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be393ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Actors: Shared State Across Workers\n",
    "#\n",
    "# Unlike tasks (stateless), actors keep state in a dedicated worker process.\n",
    "# Multiple workers can send messages to the same actor to read/write shared data.\n",
    "#\n",
    "# ┌────────────────────────────────────────────────────────────────┐\n",
    "# │  Worker Process (dedicated to this actor)                      │\n",
    "# │  ┌──────────────────────────────────────┐                      │\n",
    "# │  │  DataStore instance                  │                      │\n",
    "# │  │  self.data = {\"key_0\": 0, \"key_1\": 1, ...}                  │\n",
    "# │  └──────────────────────────────────────┘                      │\n",
    "# └────────────────────────────────────────────────────────────────┘\n",
    "#         ^           ^           ^\n",
    "#         |           |           |\n",
    "#    store.put    store.put   store.get\n",
    "#    .remote()    .remote()   .remote()\n",
    "#         |           |           |\n",
    "# ┌───────┴───┐ ┌─────┴─────┐ ┌───┴───────┐\n",
    "# │ worker 0  │ │ worker 1  │ │  driver   │\n",
    "# └───────────┘ └───────────┘ └───────────┘\n",
    "\n",
    "@ray.remote\n",
    "class DataStore:\n",
    "    \"\"\"An actor that holds a dictionary - state persists across all method calls.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = {}  # This lives for the actor's lifetime\n",
    "\n",
    "    def put(self, key, value):\n",
    "        self.data[key] = value\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data.get(key)\n",
    "\n",
    "@ray.remote\n",
    "def worker(store, key, value):\n",
    "    \"\"\"A task that writes to the shared DataStore actor.\"\"\"\n",
    "    # store is an ActorHandle, not the object itself\n",
    "    # .remote() sends an async message to the actor (doesn't wait)\n",
    "    ray.get(store.put.remote(key, value))  # Wait for put to complete\n",
    "    return f\"Stored {key}\"\n",
    "\n",
    "# 1. Create ONE DataStore instance (lives in its own worker process)\n",
    "store = DataStore.remote()  # Returns ActorHandle, not the object\n",
    "\n",
    "# 2. Launch 10 workers - all share the SAME store\n",
    "#    Each worker sends a put() message to the actor\n",
    "refs = [worker.remote(store, f\"key_{i}\", i) for i in range(10)]\n",
    "ray.get(refs)  # Wait for all workers to finish\n",
    "\n",
    "# 3. All data is now in the actor's self.data dict\n",
    "#    store.get.remote() sends a message to the actor and returns a Future\n",
    "print(ray.get(store.get.remote(\"key_5\")))  # 5\n",
    "print(ray.get(store.get.remote(\"key_10\")))  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0077848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker-1 did work\n",
      "\u001b[36m(Worker pid=23469)\u001b[0m Worker worker-1 started\n",
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"0034eab4-36b3-4217-a570-6c9e892633e5\", ...)\n",
      "global did work\n",
      "global did work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Worker pid=23472)\u001b[0m Worker global started\n"
     ]
    }
   ],
   "source": [
    "# Actor Lifecycle\n",
    "#\n",
    "# REGULAR ACTORS: tied to the driver that created them\n",
    "# ┌─────────────────┐                    ┌─────────────────┐\n",
    "# │  Driver Process │  Worker.remote()   │  Worker Process │\n",
    "# │  worker = ──────┼───────────────────>│  Actor instance │\n",
    "# │  (driver exits) │                    │  (actor dies)   │\n",
    "# └─────────────────┘                    └─────────────────┘\n",
    "#\n",
    "# NAMED + DETACHED ACTORS: survive driver exit, retrievable by name\n",
    "# ┌─────────────────┐                    ┌─────────────────┐\n",
    "# │  Driver 1       │  options(name=..., │  Worker Process │\n",
    "# │  creates actor──┼─ lifetime=detached)│  Actor instance │\n",
    "# │  (driver exits) │                    │  (STILL ALIVE!) │\n",
    "# └─────────────────┘                    │                 │\n",
    "# ┌─────────────────┐                    │                 │\n",
    "# │  Driver 2       │  get_actor(name)   │                 │\n",
    "# │  retrieves ─────┼───────────────────>│  Same instance! │\n",
    "# └─────────────────┘                    └─────────────────┘\n",
    "#\n",
    "# | Actor Type | Dies When                          |\n",
    "# |------------|-------------------------------------|\n",
    "# | Regular    | Driver exits or ray.kill()         |\n",
    "# | Named      | Driver exits or ray.kill()         |\n",
    "# | Detached   | Only ray.kill()                    |\n",
    "\n",
    "@ray.remote\n",
    "class Worker:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        print(f\"Worker {name} started\")\n",
    "    \n",
    "    def work(self):\n",
    "        return f\"{self.name} did work\"\n",
    "\n",
    "# 1. Create a regular actor (dies when driver exits)\n",
    "worker = Worker.remote(\"worker-1\")\n",
    "print(ray.get(worker.work.remote()))\n",
    "\n",
    "# 2. Kill gracefully (waits for current task to finish)\n",
    "#    force=True would interrupt immediately\n",
    "ray.kill(worker, no_restart=True)\n",
    "\n",
    "# 3. Create a NAMED + DETACHED actor\n",
    "#    - name: retrievable from anywhere in cluster via ray.get_actor()\n",
    "#    - lifetime=\"detached\": survives even if this notebook closes\n",
    "named_worker = Worker.options(\n",
    "    name=\"global_worker\",\n",
    "    lifetime=\"detached\",\n",
    "    # Other options:\n",
    "    # num_cpus=2,          # Reserve 2 CPUs\n",
    "    # num_gpus=1,          # Reserve 1 GPU\n",
    "    # max_restarts=3,      # Auto-restart on failure\n",
    "    # max_concurrency=10,  # Handle 10 concurrent calls (async)\n",
    ").remote(\"global\")\n",
    "\n",
    "print(ray.get(named_worker.work.remote()))\n",
    "\n",
    "# 4. Get existing actor by name (works from ANY process in the cluster)\n",
    "same_worker = ray.get_actor(\"global_worker\")\n",
    "print(ray.get(same_worker.work.remote()))  # Same actor!\n",
    "\n",
    "# 5. Clean up - must explicitly kill detached actors\n",
    "ray.kill(named_worker, no_restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeez710zd1q",
   "metadata": {},
   "source": "---\n\n## 5. Object Store: The Secret Sauce\n\nThe **Object Store** (Plasma) is shared memory that all workers can access. This is what makes Ray fast.\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                              SINGLE NODE                                │\n│                                                                         │\n│    ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐            │\n│    │ Worker  │    │ Worker  │    │ Worker  │    │ Worker  │            │\n│    └────┬────┘    └────┬────┘    └────┬────┘    └────┬────┘            │\n│         │              │              │              │                  │\n│         └──────────────┴──────┬───────┴──────────────┘                  │\n│                               │                                         │\n│                    ┌──────────▼──────────┐                              │\n│                    │    OBJECT STORE     │                              │\n│                    │   (Shared Memory)   │                              │\n│                    │                     │                              │\n│                    │  [array1] [array2]  │                              │\n│                    │  [model]  [config]  │                              │\n│                    └─────────────────────┘                              │\n│                                                                         │\n│    Key insight: Workers don't copy data. They read directly from        │\n│    shared memory. NumPy arrays are ZERO-COPY!                           │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n### ObjectRef: The Pointer\n\nWhen a task returns, the result goes into the object store. You get an `ObjectRef` back - it's just a pointer, not the data itself."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ea193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectRef(e5b2fae6e42f6bbaffffffffffffffffffffffff0100000001000000)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# The object store\n",
    "@ray.remote\n",
    "def create_array():\n",
    "    import numpy as np\n",
    "    return np.zeros((10000, 10000))  # ~800MB\n",
    "\n",
    "ref = create_array.remote()  # Returns immediately with ObjectRef\n",
    "print(ref)  # ObjectRef(...)\n",
    "\n",
    "# The 800MB array is in the object store, not in your process\n",
    "# ref is just a pointer to it\n",
    "# obtain the actual object with ray.get()\n",
    "array = ray.get(ref)  # Blocks until the object is ready\n",
    "print(array.shape)  # (10000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeqwismo63n",
   "metadata": {},
   "source": "### Zero-Copy Reads (NumPy/Arrow)\n\nFor NumPy arrays and Arrow tables, Ray uses **zero-copy deserialization**. Multiple workers read the same data without copying:\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│  Object Store                                                           │\n│  ┌───────────────────────────────────────────────────────┐              │\n│  │  numpy_array (800MB)                                   │              │\n│  │  [████████████████████████████████████████████████]   │              │\n│  └───────────────────────────────────────────────────────┘              │\n│         ▲              ▲              ▲              ▲                   │\n│         │              │              │              │                   │\n│    (zero-copy)    (zero-copy)   (zero-copy)    (zero-copy)              │\n│         │              │              │              │                   │\n│    ┌────┴────┐    ┌────┴────┐   ┌────┴────┐    ┌────┴────┐             │\n│    │ Worker1 │    │ Worker2 │   │ Worker3 │    │ Worker4 │             │\n│    │ arr.sum │    │ arr.mean│   │ arr.std │    │ arr.max │             │\n│    └─────────┘    └─────────┘   └─────────┘    └─────────┘             │\n│                                                                         │\n│    No copies made! All workers read the same memory location.           │\n└─────────────────────────────────────────────────────────────────────────┘\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_ref:  ObjectRef(278af2822d9a793affffffffffffffffffffffff0100000001000000)\n",
      "[np.float64(49999601.18804898), np.float64(49999601.18804898), np.float64(49999601.18804898), np.float64(49999601.18804898), np.float64(49999601.18804898)]\n"
     ]
    }
   ],
   "source": [
    "# Zero-copy Reads\n",
    "import numpy as np\n",
    "\n",
    "@ray.remote\n",
    "def create_data():\n",
    "    data = np.random.random((10000, 10000))  # ~800MB\n",
    "    return data\n",
    "\n",
    "@ray.remote\n",
    "def process_data(data):\n",
    "    # data is not copied - zero-copy read from object store\n",
    "    return np.sum(data)\n",
    "\n",
    "data_ref = create_data.remote()\n",
    "print(\"data_ref: \", data_ref)\n",
    "# Launch 10 tasks that all read the same data\n",
    "# NO COPYING - all 10 workers read from the same shared memory\n",
    "refs = [process_data.remote(data_ref) for _ in range(5)]\n",
    "results = ray.get(refs)\n",
    "print(results)  # [0.0, 0.0, ..., 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad (pass data):  16.23s\n",
      "Good (pass ref):  2.30s\n",
      "Speedup: 7.1x\n",
      "Results (all same): 49998857.32\n"
     ]
    }
   ],
   "source": [
    "# Put data in object store explicitly\n",
    "#\n",
    "# ray.put() stores data once, then you pass the ref to many tasks.\n",
    "# Ray AUTO-RESOLVES refs when passed to tasks - no ray.get() needed inside!\n",
    "#\n",
    "# ┌─────────────────────────────────────────────────────────────────┐\n",
    "# │  Object Store (shared memory)                                   │\n",
    "# │  ┌─────────────────────────────────────┐                        │\n",
    "# │  │  large_array (800MB, stored ONCE)   │                        │\n",
    "# │  └─────────────────────────────────────┘                        │\n",
    "# └─────────────────────────────────────────────────────────────────┘\n",
    "#         ^           ^           ^\n",
    "#         |           |           |  (zero-copy reads)\n",
    "#    process()   process()   process()\n",
    "#\n",
    "# GOOD: ray.put() once, pass ref 10 times  -> 1 copy in memory\n",
    "# BAD:  pass array directly 10 times       -> 10 copies serialized\n",
    "#\n",
    "# Object store config:\n",
    "#   ray.init(object_store_memory=10 * 1024 * 1024 * 1024)  # 10GB\n",
    "#   Default: 30% of RAM\n",
    "#\n",
    "# Reference counting:\n",
    "#   ref = ray.put(data)\n",
    "#   del ref  # Object becomes eligible for garbage collection\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "large_array = np.random.rand(10000, 10000)  # ~800MB\n",
    "ref = ray.put(large_array)  # Store once in object store\n",
    "\n",
    "@ray.remote\n",
    "def process(data):\n",
    "    # data is ALREADY the numpy array (Ray auto-resolved the ref)\n",
    "    # DO NOT call ray.get() here!\n",
    "    return data.sum()\n",
    "\n",
    "# Bad: Pass data directly (serialized 10 times!)\n",
    "start = time.time()\n",
    "results = ray.get([process.remote(large_array) for _ in range(5)])\n",
    "bad_time = time.time() - start\n",
    "print(f\"Bad (pass data):  {bad_time:.2f}s\")\n",
    "\n",
    "# Good: Pass ref - Ray resolves it automatically, zero-copy\n",
    "start = time.time()\n",
    "results = ray.get([process.remote(ref) for _ in range(5)])\n",
    "good_time = time.time() - start\n",
    "print(f\"Good (pass ref):  {good_time:.2f}s\")\n",
    "print(f\"Speedup: {bad_time / good_time:.1f}x\")\n",
    "print(f\"Results (all same): {results[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zepy09dufu",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Summary: Patterns & Anti-Patterns\n",
    "\n",
    "### The Good (Do This)\n",
    "\n",
    "```python\n",
    "# 1. Batch submissions - submit all, then wait\n",
    "refs = [task.remote(i) for i in range(1000)]\n",
    "results = ray.get(refs)\n",
    "\n",
    "# 2. Use ray.put() for shared data\n",
    "data_ref = ray.put(large_data)  # 1 serialization\n",
    "refs = [process.remote(data_ref) for _ in range(100)]  # Just passing refs\n",
    "\n",
    "# 3. Process results as they arrive\n",
    "while refs:\n",
    "    ready, refs = ray.wait(refs, num_returns=1)\n",
    "    handle_result(ray.get(ready[0]))\n",
    "\n",
    "# 4. Use actors for expensive resources\n",
    "@ray.remote(num_gpus=1)\n",
    "class ModelServer:\n",
    "    def __init__(self):\n",
    "        self.model = load_heavy_model()  # Only loaded once!\n",
    "```\n",
    "\n",
    "### The Bad (Don't Do This)\n",
    "\n",
    "```python\n",
    "# 1. DON'T submit and wait one at a time\n",
    "for i in range(1000):\n",
    "    result = ray.get(task.remote(i))  # Blocks each time!\n",
    "\n",
    "# 2. DON'T pass large data directly (serialized N times!)\n",
    "refs = [process.remote(large_data) for _ in range(100)]  # 100 copies!\n",
    "\n",
    "# 3. DON'T create too many tiny tasks\n",
    "refs = [add_one.remote(i) for i in range(1_000_000)]  # Overhead > work\n",
    "\n",
    "# 4. DON'T call ray.get() inside tasks (blocks a worker)\n",
    "@ray.remote\n",
    "def bad_task():\n",
    "    return ray.get(other_task.remote())  # Wastes a worker!\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}